{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "jDiUOXq2OfY2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9pa3tjguORpX"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = 10000"
      ],
      "metadata": {
        "id": "qb6pSt6QRsxj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)"
      ],
      "metadata": {
        "id": "wQXEC0MSPB8l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b686669-f624-4b77-856f-498464785bab"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import feature_column"
      ],
      "metadata": {
        "id": "u8Xhv1rOO3tV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb.load_data(num_words=10000)\n",
        "data = np.concatenate((X_train, X_test), axis=0)\n",
        "targets = np.concatenate((y_train, y_test), axis=0)"
      ],
      "metadata": {
        "id": "BCRqikVIQQ_Y"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Categories:\", np.unique(targets))\n",
        "print(\"Number of unique words:\", len(np.unique(np.hstack(data))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRt7hil8hxCi",
        "outputId": "8ac353d9-2262-4576-e42f-27cd066849ee"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Categories: [0 1]\n",
            "Number of unique words: 9998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length = [len(i) for i in data]\n",
        "print(\"Average Review length:\", np.mean(length))\n",
        "print(\"Standard Deviation:\", round(np.std(length)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93WYt2T4hxFG",
        "outputId": "b988490d-40b5-449a-f951-23e85a1de9a6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Review length: 234.75892\n",
            "Standard Deviation: 173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = imdb.get_word_index()\n",
        "reverse_index = dict([(value, key) for (key, value) in index.items()]) \n",
        "decoded = \" \".join( [reverse_index.get(i - 3, \"#\") for i in data[0]] )\n",
        "print(decoded) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvxQcC4LhxGr",
        "outputId": "abe8c437-05bb-463c-fc14-eb757f8f0468"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n",
            "# this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert # is an amazing actor and now the same being director # father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for # and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also # to the two little boy's that played the # of norman and paul they were just brilliant children are often left out of the # list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(sequences, dimension = 10000):\n",
        "  results = np.zeros((len(sequences), dimension))\n",
        "  for i, sequence in enumerate(sequences):\n",
        "    results[i, sequence] = 1\n",
        "  return results\n",
        "data = vectorize(data)\n",
        "targets = np.array(targets).astype(\"float32\")"
      ],
      "metadata": {
        "id": "cMr6cJB9iV32"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = data[:10000]\n",
        "test_y = targets[:10000]\n",
        "train_x = data[10000:]\n",
        "train_y = targets[10000:]"
      ],
      "metadata": {
        "id": "c2wHsOQyhxIf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import Sequential"
      ],
      "metadata": {
        "id": "Vz14cllZi-Jt"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "# Input - Layer\n",
        "model.add(layers.Dense(50, activation = \"relu\", input_shape=(10000, )))\n",
        "# Hidden - Layers\n",
        "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
        "model.add(layers.Dense(1024, activation = \"relu\"))\n",
        "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
        "model.add(layers.Dense(2, activation = \"relu\"))\n",
        "# Output- Layer\n",
        "model.add(layers.Dense(1, activation = \"sigmoid\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QlhdJayhxKU",
        "outputId": "b4a82d72-f784-46d6-a8b6-562bd2b21d1f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 50)                500050    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 50)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1024)              52224     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 2050      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 3         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 554,327\n",
            "Trainable params: 554,327\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "cQUUBGEShxRW"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = model.fit(\n",
        " train_x, train_y,\n",
        " epochs= 20,\n",
        " batch_size = 512,\n",
        " validation_data = (test_x, test_y)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPkVwwSJhxTb",
        "outputId": "a1a203e5-7661-43eb-f29d-e8fa5b853adb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "79/79 [==============================] - 6s 71ms/step - loss: 0.3896 - accuracy: 0.8213 - val_loss: 0.2617 - val_accuracy: 0.8940\n",
            "Epoch 2/20\n",
            "79/79 [==============================] - 5s 67ms/step - loss: 0.2026 - accuracy: 0.9209 - val_loss: 0.2665 - val_accuracy: 0.8939\n",
            "Epoch 3/20\n",
            "79/79 [==============================] - 5s 65ms/step - loss: 0.1380 - accuracy: 0.9490 - val_loss: 0.3260 - val_accuracy: 0.8847\n",
            "Epoch 4/20\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.0896 - accuracy: 0.9694 - val_loss: 0.3521 - val_accuracy: 0.8874\n",
            "Epoch 5/20\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.0568 - accuracy: 0.9817 - val_loss: 0.4471 - val_accuracy: 0.8843\n",
            "Epoch 6/20\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.0428 - accuracy: 0.9855 - val_loss: 0.4667 - val_accuracy: 0.8803\n",
            "Epoch 7/20\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.5051 - val_accuracy: 0.8809\n",
            "Epoch 8/20\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.0296 - accuracy: 0.9893 - val_loss: 0.5746 - val_accuracy: 0.8804\n",
            "Epoch 9/20\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.0272 - accuracy: 0.9904 - val_loss: 0.6523 - val_accuracy: 0.8793\n",
            "Epoch 10/20\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.0278 - accuracy: 0.9900 - val_loss: 0.6368 - val_accuracy: 0.8793\n",
            "Epoch 11/20\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.0229 - accuracy: 0.9916 - val_loss: 0.6804 - val_accuracy: 0.8778\n",
            "Epoch 12/20\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.0228 - accuracy: 0.9919 - val_loss: 0.6598 - val_accuracy: 0.8819\n",
            "Epoch 13/20\n",
            "79/79 [==============================] - 7s 83ms/step - loss: 0.0235 - accuracy: 0.9918 - val_loss: 0.6899 - val_accuracy: 0.8796\n",
            "Epoch 14/20\n",
            "79/79 [==============================] - 6s 75ms/step - loss: 0.0197 - accuracy: 0.9929 - val_loss: 0.6466 - val_accuracy: 0.8794\n",
            "Epoch 15/20\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.7116 - val_accuracy: 0.8768\n",
            "Epoch 16/20\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.0202 - accuracy: 0.9930 - val_loss: 0.6636 - val_accuracy: 0.8792\n",
            "Epoch 17/20\n",
            "79/79 [==============================] - 5s 67ms/step - loss: 0.0141 - accuracy: 0.9952 - val_loss: 0.7112 - val_accuracy: 0.8798\n",
            "Epoch 18/20\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.7411 - val_accuracy: 0.8786\n",
            "Epoch 19/20\n",
            "79/79 [==============================] - 5s 67ms/step - loss: 0.0133 - accuracy: 0.9952 - val_loss: 0.7387 - val_accuracy: 0.8797\n",
            "Epoch 20/20\n",
            "79/79 [==============================] - 5s 66ms/step - loss: 0.0127 - accuracy: 0.9955 - val_loss: 0.6950 - val_accuracy: 0.8798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(results.history['accuracy']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvq-Pz7NliRp",
        "outputId": "6a9ea68a-864a-490f-f28f-7764e7c34baf"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9761299967765809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(results.history['loss']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhzk6kyGhe_2",
        "outputId": "de0c72f1-3e85-4b58-baf5-9551e8248766"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06092624720185995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "707rEaXRmgEF"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "k3IpDEodmrmG"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P5CosRomrqO",
        "outputId": "51ecf214-85d7-4df2-bf7d-320bd9bb1596"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label=[]\n",
        "sentence=[]\n",
        "with open('/content/drive/MyDrive/Datasets/yelp_labelled.txt') as f:\n",
        "  lines = f.readlines()\n",
        "for line in lines:\n",
        "  label.append(int(line[-2]))\n",
        "  sentence.append(line[:-3])"
      ],
      "metadata": {
        "id": "DmeP9bgCz-9i"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'feature':sentence, 'target':label})"
      ],
      "metadata": {
        "id": "JSlA13-FnyYD"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_train=[]\n",
        "sentences_test=[]\n",
        "for i in range(700):\n",
        "  sentences_train.append(df.feature[i])\n",
        "for j in range(700,1000):\n",
        "  sentences_test.append(df.feature[i])"
      ],
      "metadata": {
        "id": "YaToo3nHnyaW"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=5000)\n",
        "tokenizer.fit_on_texts(sentences_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
        "X_test = tokenizer.texts_to_sequences(sentences_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(sentences_train[2])\n",
        "print(X_train[2])"
      ],
      "metadata": {
        "id": "LSYkMfzQnycK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359ed468-a89a-4835-fd65-b8e18c1d29f3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not tasty and the texture was just nasty.\n",
            "[14, 143, 2, 1, 432, 3, 45, 433]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = df.target[:700]\n",
        "y_test = df.target[700:]"
      ],
      "metadata": {
        "id": "Lc78cQChnyfq"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in ['the', 'all', 'happy', 'sad']:\n",
        "  print('{}: {}'.format(word, tokenizer.word_index[word]))"
      ],
      "metadata": {
        "id": "4FqSJEyOmrsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b285c109-7d9d-428b-8f3c-cacbc22d7e3e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the: 1\n",
            "all: 41\n",
            "happy: 212\n",
            "sad: 540\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "maxlen = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
      ],
      "metadata": {
        "id": "WZuY5x6o5CNT"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv1D, GlobalMaxPooling1D, Embedding\n",
        "from keras.layers import Activation, Dense"
      ],
      "metadata": {
        "id": "bgwJungr5CSe"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Sequential()\n",
        "\n",
        "embedding_dim = 50\n",
        "maxlen= 100\n",
        "num_filters= 64\n",
        "kernel_size=5\n",
        "\n",
        "model_1.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
        "model_1.add(Conv1D(64, 5, input_shape=(1,4), activation='relu'))\n",
        "model_1.add(GlobalMaxPooling1D())\n",
        "model_1.add(Dense(10,activation='relu'))\n",
        "model_1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_1.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDJIbu065INX",
        "outputId": "979679da-a294-4548-f14b-9296ef8c9ad5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 50)           83000     \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 96, 64)            16064     \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Glo  (None, 64)               0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 99,725\n",
            "Trainable params: 99,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_1 = model_1.fit(X_train, y_train,epochs=20,verbose=False,validation_data=(X_test, y_test),batch_size=32)"
      ],
      "metadata": {
        "id": "mRHeCQXK5IQP"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = model_1.evaluate(X_train, y_train, verbose=False)\n",
        "print(\"Training: Loss: {:.4f}\".format(train_acc[0]), \"Accuracy: {:.4f}\".format(train_acc[1]))\n",
        "test_acc = model_1.evaluate(X_test, y_test, verbose=False)\n",
        "print(\"Testing Loss: {:.4f}\".format(test_acc[0]), \"Accuracy:  {:.4f}\".format(test_acc[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4grFWEa5IS1",
        "outputId": "38bf0641-3b8f-41e8-fe51-3676e3a69d06"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: Loss: 0.0012 Accuracy: 1.0000\n",
            "Testing Loss: 2.0353 Accuracy:  0.6400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "flhS5SK75IVL"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Ew6V13H5IXQ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O5tMyFDK5IZ3"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WOcziimq5CwP"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MtBmpilj5Cyw"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#References : \n",
        "#1. https://builtin.com/data-science/how-build-neural-network-keras"
      ],
      "metadata": {
        "id": "bw3FyKzcmruJ"
      },
      "execution_count": 66,
      "outputs": []
    }
  ]
}